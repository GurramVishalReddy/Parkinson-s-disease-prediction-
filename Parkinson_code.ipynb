{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUAXPRFLmQy28VeELoQE6o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GurramVishalReddy/Parkinson-s-disease-prediction-/blob/main/Parkinson_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwFGObDhZKB4",
        "outputId": "115cd3d2-3dde-4361-fcf4-1c6835a61276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.27.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.9.0 (from gradio)\n",
            "  Downloading gradio_client-1.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.27.0-py3-none-any.whl (54.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.9.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.6/322.6 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.27.0 gradio-client-1.9.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.7 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install praat-parselmouth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uJdDpngZanc",
        "outputId": "7ecb7ce3-618e-4f43-82d1-f71da396884c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praat-parselmouth\n",
            "  Downloading praat_parselmouth-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from praat-parselmouth) (2.0.2)\n",
            "Downloading praat_parselmouth-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: praat-parselmouth\n",
            "Successfully installed praat-parselmouth-0.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import gradio as gr\n",
        "import parselmouth\n",
        "from parselmouth.praat import call\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix\n",
        ")\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/Vishu Dataset.csv\")\n",
        "X = df.drop(columns=[\"name\", \"status\"])\n",
        "y = df[\"status\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.25, stratify=y_resampled, random_state=42\n",
        ")\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
        "knn = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
        "knn_bagged = BaggingClassifier(estimator=knn, n_estimators=10, random_state=42)\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        (\"Random Forest\", rf),\n",
        "        (\"Bagged KNN\", knn_bagged)\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "def extract_22_features(file_path):\n",
        "    y, sr = librosa.load(file_path)\n",
        "\n",
        "    duration = librosa.get_duration(y=y, sr=sr)\n",
        "    amplitude = np.max(np.abs(y)) if len(y) > 0 else 0\n",
        "    print(f\"Audio Duration: {duration}s, Max Amplitude: {amplitude}\")\n",
        "\n",
        "    snd = parselmouth.Sound(file_path)\n",
        "    if snd.duration < 0.3:\n",
        "        raise ValueError(\"Audio too short. Please upload a longer voice sample.\")\n",
        "\n",
        "    point_process = call(snd, \"To PointProcess (periodic, cc)\", 75, 500)\n",
        "    pitch = call(snd, \"To Pitch\", 0.0, 75, 600)\n",
        "\n",
        "    try:\n",
        "        mdvp_fo = pitch.get_mean() if pitch.get_mean() > 0 else np.nan\n",
        "        mdvp_fhi = pitch.get_maximum() if pitch.get_maximum() > 0 else np.nan\n",
        "        mdvp_flo = pitch.get_minimum() if pitch.get_minimum() > 0 else np.nan\n",
        "        jitter_local = call(point_process, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
        "        jitter_abs = call(point_process, \"Get jitter (absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
        "        mdvp_rap = call(point_process, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
        "        mdvp_ppq = call(point_process, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
        "        jitter_ddp = call(point_process, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3)\n",
        "        shimmer_local = call([snd, point_process], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
        "        mdvp_shimmer = shimmer_local * 100 if shimmer_local > 0 else np.nan\n",
        "        mdvp_shimmer_db = call([snd, point_process], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
        "        shimmer_apq3 = call([snd, point_process], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
        "        shimmer_apq5 = call([snd, point_process], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
        "        mdvp_apq = call([snd, point_process], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
        "        shimmer_dda = call([snd, point_process], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
        "        nhr = call(snd, \"Get noise to harmonics ratio (HNR)\", 0.0, 75, 600, 0.0, 0.0, \"mean\")\n",
        "        hnr = call(snd, \"Get harmonicity (cc)\", 0.01, 75, 0.1, 1.0).get_value(1)\n",
        "        print(f\"Raw Features: Fo={mdvp_fo}, Fhi={mdvp_fhi}, Jitter={jitter_local}, Shimmer={shimmer_local}, NHR={nhr}\")\n",
        "    except Exception as e:\n",
        "        mdvp_fo = mdvp_fhi = mdvp_flo = jitter_local = jitter_abs = mdvp_rap = mdvp_ppq = jitter_ddp = np.nan\n",
        "        shimmer_local = mdvp_shimmer = mdvp_shimmer_db = shimmer_apq3 = shimmer_apq5 = mdvp_apq = shimmer_dda = np.nan\n",
        "        nhr = hnr = np.nan\n",
        "        print(f\"Feature extraction error: {str(e)}\")\n",
        "\n",
        "\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr).mean()\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr).mean()\n",
        "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y).mean()\n",
        "\n",
        "\n",
        "    feature_vector = np.array([\n",
        "        mdvp_fo, mdvp_fhi, mdvp_flo,\n",
        "        jitter_local, jitter_abs,\n",
        "        mdvp_rap, mdvp_ppq, jitter_ddp,\n",
        "        mdvp_shimmer, mdvp_shimmer_db, shimmer_apq3, shimmer_apq5,\n",
        "        mdvp_apq, shimmer_dda,\n",
        "        nhr, hnr,\n",
        "        np.nan, np.nan,\n",
        "        np.nan, np.nan, np.nan,\n",
        "        np.nan\n",
        "    ])\n",
        "\n",
        "\n",
        "    X_train_df = pd.DataFrame(X_train, columns=X.columns)\n",
        "    for i, col in enumerate(X.columns):\n",
        "        if np.isnan(feature_vector[i]):\n",
        "            feature_vector[i] = X_train_df[col].mean()\n",
        "\n",
        "    return dict(zip(X.columns, feature_vector))\n",
        "\n",
        "def predict_from_voice_file(audio_file):\n",
        "    try:\n",
        "\n",
        "        features = extract_22_features(audio_file)\n",
        "\n",
        "        features_df = pd.DataFrame([features], columns=X.columns)\n",
        "        features_scaled = scaler.transform(features_df)\n",
        "\n",
        "        proba = voting_clf.predict_proba(features_scaled)[0, 1]\n",
        "        prediction = 1 if proba >= 0.5 else 0\n",
        "\n",
        "        prediction_text = \"🧠 Parkinson's Detected\" if prediction == 1 else \"✅ No Parkinson's Detected\"\n",
        "\n",
        "        metrics = {\n",
        "            \"Accuracy\": accuracy_score(y_test, voting_clf.predict(X_test)),\n",
        "            \"Precision\": precision_score(y_test, voting_clf.predict(X_test)),\n",
        "            \"Recall\": recall_score(y_test, voting_clf.predict(X_test)),\n",
        "            \"F1 Score\": f1_score(y_test, voting_clf.predict(X_test)),\n",
        "            \"ROC AUC\": roc_auc_score(y_test, voting_clf.predict_proba(X_test)[:,1]),\n",
        "        }\n",
        "        metrics_str = \"\\n\".join([f\"{k}: {v:.2f}\" for k, v in metrics.items()])\n",
        "\n",
        "\n",
        "        features_str = \"\\n\".join([f\"{k}: {v:.4f}\" for k, v in features.items()])\n",
        "\n",
        "\n",
        "        output = f\"{prediction_text}\\n\\n📊 Extracted Features:\\n{features_str}\\n\\n📊 Model Metrics:\\n{metrics_str}\"\n",
        "\n",
        "        return output\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"❌ Error processing the file: {str(e)}\"\n",
        "\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=predict_from_voice_file,\n",
        "    inputs=gr.Audio(type=\"filepath\", label=\"Upload Voice Sample (.wav)\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Parkinson's Disease Prediction\",\n",
        "    description=\"This app predicts Parkinson’s Disease from voice by extracting 22 biomedical features from your audio.\"\n",
        ")\n",
        "\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "6UqzWI8KZdJR",
        "outputId": "fe214966-34ea-4e73-c1bb-5975bb84338b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://93d63427100d7a2217.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://93d63427100d7a2217.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}